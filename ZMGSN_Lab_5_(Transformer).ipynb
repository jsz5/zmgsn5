{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAAlwlConUZO"
   },
   "source": [
    "<h1>ZMGSN Lista 5. - Architektura Sieci typu Transformer</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWsT6r5JgTsw"
   },
   "source": [
    "<h2>Opis zadania</h2>\n",
    "\n",
    "W ramach zadania należy:\n",
    "<ol>\n",
    "<li>Zapoznać się z poniższym eksperymentem z wykorzystaniem sieci typu Transformer</li>\n",
    "<li>Dokonać analizy wpływu hiperparametrów eksperymentu, np. kroku uczenia, rozmiaru pakietu (ang. <i>batch size</i>), liczby epok na wyniki sieci typu Transformer (10pkt)</li>\n",
    "<li>Wykorzystać inne architektury wstępnie wyuczonych sieci typu Transformer (np. RoBERTa, XLM-RoBERTa, DistilBERT, AlBERT, DeBERTa, XLNet, MPNet, LaBSE itp.) w celu uzasadnienia w jaki sposób ich architektura, sposób uczenia i zbiór uczący mogły mieć wpływ na wyniki (30pkt)</li>\n",
    "<li>Wykorzystać inne rozmiary wstępnie wyuczonych sieci typu Transformer w celu uzasadnienia w jaki sposób ich architektura, sposób uczenia i zbiór uczący mogły mieć wpływ na wyniki - porównać modele o tej samej architekturze, ale różnych rozmiarach np. (XLM-RoBERTa-base, XLM-RoBERTa-large) (20pkt)</li>\n",
    "<li>Dokonać modyfikacji rozszerzenia wstępnie wyuczonej sieci typu Transformer w celu zbadania wpływu architektury na wyniki (5pkt)</li>\n",
    "<li>Zaimplementować własne warianty rozszerzeń architektury wstępnie wyuczonej sieci typu Transformer w celu zbadania ich wpływu na wyniki (15pkt)</li>\n",
    "<li>Zbadać wpływ maksymalnej długości tekstu oraz różnych strategii paddingu dla każdego z wykorzystanych wstępnie wyuczonych modeli (20 pkt)</li>\n",
    "<li>Dokonać ewaluacji różnych wstępnie wyuczonych modeli sieci typu Transformer (różne rozmiary modeli oraz typy), modyfikacji oryginalnego rozszerzenia oraz opracowanych rozszerzeń zgodnie z punktami 2., 5., 6. i 7.  </li>\n",
    "<li>Dokonać usystematyzowanej ewaluacji porównawczej wszystkich modeli sieci typu transformer, ich wariantów, wykorzystanych rozszerzeń w celu zbadania różnic, podobieństw oraz analogicznych cech ich charakterystyki.</li>\n",
    "<li>Opracować procedurę ewaluacji jakości działania modeli sieci typu Transformer, uwzględniającą różne metody wizualizacji (np. wykresy, miary, klasy), klasteryzacji, redukcji wymiarów (np. t-SNE), walidacji krzyżowej, wpływu charakterystyki zbioru uczącego na działanie modelu, podatności na semantykę tekstów w zbiorze uczącym i testowym itp. </li>\n",
    "</ol>\n",
    "\n",
    "Należy przygotować raport w LaTeX, który będzie zawierać opis architektury typu Transformer, opis wybranych architektur, opis wykonanych eksperymentów, opis procedury ewaluacji, wyniki ewaluacji oraz wnioski. Ocena za raport będzie stanowić 50% oceny za listę. Maksymalna liczba punktów za każde zadanie będzie przyznana za implementację oraz kompletny opis w raporcie. Punkty za zadania 2-7 będą przyznane za implementację oraz ewaluację. \n",
    " \n",
    "Ocenie podlegać będzie jakość wykonania zadania, w tym:\n",
    "<ol>\n",
    "<li>Właściwe wykonanie zadań</li>\n",
    "<li>Rzetelne opracowanie wyników, uwzględniające analizę jakościową i ilościową</li>\n",
    "<li>Opracowanie wniosków mających na celu wyjaśnienie badanych zjawisk i uzyskanych wyników</li>\n",
    "<li>Opracowanie i wyjaśnienie kodu źródłowego</li>\n",
    "<li>Raport </li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-O7Iq3oxsee"
   },
   "source": [
    "<h2>Import używanych bibliotek</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1702507939174,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "OFMDF6cQlZQp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Clbf6e9oNwV"
   },
   "source": [
    "<h2>Inicjalizacja ziarna generatora liczb pseudolosowych</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1702507939515,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "HEcf9rHloODn",
    "outputId": "8169d2cc-e882-4db4-8ddf-11121baf7d5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7bf62b3a59d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIQql1pXDNW7"
   },
   "source": [
    "<h2>Określenie domyślnego urządzenia na podstawie sprawdzenia dostępności karty graficznej</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1702507939516,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "--ASGwcxDZ2y",
    "outputId": "90356fa7-1e1d-4cfc-9d10-3eeec3f40aa7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Mt9fso20I1d"
   },
   "source": [
    "<h2>Pobranie i rozpakowanie zbioru danych</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702507939516,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "3vai6EaaMeLA"
   },
   "outputs": [],
   "source": [
    "if os.path.exists('data.csv'):\n",
    "  os.remove('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 1200,
     "status": "ok",
     "timestamp": 1702507940713,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "QbtUfX1xgTs8",
    "outputId": "a7179c6f-4bbf-4616-97ff-c5088fb605d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1HSnB-D0dKDI2bE9iOsp-Vr8tumihdvbH\n",
      "To: /content/data.csv\n",
      "100%|██████████| 467k/467k [00:00<00:00, 111MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'data.csv'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://drive.google.com/uc?id=1HSnB-D0dKDI2bE9iOsp-Vr8tumihdvbH'\n",
    "output = 'data.csv'\n",
    "\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piaR0aRONy3h"
   },
   "source": [
    "<h2>Wczytanie zbioru danych</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1702507940713,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "PIzwCVsbN4fJ",
    "outputId": "977b8888-ab53-4707-c64d-a140b298ccef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7bad2fc5-e992-4a6c-a996-57ec1f7c1b7d\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bad2fc5-e992-4a6c-a996-57ec1f7c1b7d')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-7bad2fc5-e992-4a6c-a996-57ec1f7c1b7d button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-7bad2fc5-e992-4a6c-a996-57ec1f7c1b7d');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-f3059be6-487c-41e9-9f89-d168303db53c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3059be6-487c-41e9-9f89-d168303db53c')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-f3059be6-487c-41e9-9f89-d168303db53c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzPdmxtIEe57"
   },
   "source": [
    "<h2>Podział zbioru na podzbiór uczący i testowy</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1702507940713,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "DMszQMdREsoD"
   },
   "outputs": [],
   "source": [
    "train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'],\n",
    "                                                                    random_state=2018,\n",
    "                                                                    test_size=0.3,\n",
    "                                                                    stratify=df['label'])\n",
    "\n",
    "\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels,\n",
    "                                                                random_state=2018,\n",
    "                                                                test_size=0.5,\n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26T187r-E3O2"
   },
   "source": [
    "<h2>Pobranie modelu wstępnie wyuczonej sieci typu Transformer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 3649,
     "status": "ok",
     "timestamp": 1702507944357,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "DjEnBMDyE32i"
   },
   "outputs": [],
   "source": [
    "# Pobranie oraz wczytanie modelu transformera\n",
    "pretrained_model = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Pobranie oraz wczytanie dedykowanego tokenizatora\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HN0ALw3iGM4D"
   },
   "source": [
    "<h2>Tokenizacja oraz wygenerowanie wektorowych reprezentacji tekstów</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1702507944924,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "nZqltHaUGNcC"
   },
   "outputs": [],
   "source": [
    "# Tokenizacja i wygenerowanie reprezentacji wektorowych tekstów ze zbioru uczącego\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 25,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# Tokenizacja i wygenerowanie reprezentacji wektorowych tekstów ze zbioru walidacyjnego\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 25,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# Tokenizacja i wygenerowanie reprezentacji wektorowych tekstów ze zbioru testowego\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 25,\n",
    "    padding='max_length',\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPq42WoDPgEM"
   },
   "source": [
    "<h2>Konwersja list na tensory</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702507944924,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "Jk7HizvhPnRv"
   },
   "outputs": [],
   "source": [
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkyNL1-qPrtk"
   },
   "source": [
    "<h2>Przygotowanie instancji klas typu DataLoader</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702507944924,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "f0SY3lDfPr_8"
   },
   "outputs": [],
   "source": [
    "# Określenie rozmiaru pakietu (ang. batch size)\n",
    "batch_size = 32\n",
    "\n",
    "# Utworzenie obiektu klasy nadrzędnej dla zbiorów: uczącego, walidacyjnego i teestowego\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# Przygotowanie obiektu klasy pozwalającej na próbkowanie zbioru uczącego\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# Przygotowanie obhiektu klasy DataLoader dla zbioru uczącego\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Przygotowanie klasy nadrzędnej dla zbioru walidacyjnego\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# Przygotowanie obiektu klasy pozwalającej na próbkowanie zbioru uczącego\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# Przygotowanie obhiektu klasy DataLoader dla zbioru walidacyjnego\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MWRYVrcQmqo"
   },
   "source": [
    "<h2>Przygotowanie rozszerzenia architektury wstępnie wyuczonego modelu sieci typu Transformer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1702507944924,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "8WoBQ3BbQ2NS"
   },
   "outputs": [],
   "source": [
    "# Zamrozenie wszystkich parametrów pierwotnej sieci\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702507944925,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "z1U2Is9bQ-2L"
   },
   "outputs": [],
   "source": [
    "class Ext_Arch(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(Ext_Arch, self).__init__()\n",
    "\n",
    "        self.pretrained_model = pretrained_model\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "        _, cls_hs = self.pretrained_model(sent_id, attention_mask=mask, return_dict=False)\n",
    "\n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        x = self.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzXpdeqCSXzL"
   },
   "source": [
    "<h2>Konfiguracja eksperymentu</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702507944925,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "idF9X16ZRSkx"
   },
   "outputs": [],
   "source": [
    "# Inicjalizacja rozszerzonej architektury pierwotnym modelem\n",
    "model = Ext_Arch(pretrained_model)\n",
    "\n",
    "# Przeniesienie modelu do pamięci domyślnego urządzenia\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702507944925,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "cSuChoZhRgAr",
    "outputId": "9b5396a5-2fb0-413a-f520-4ae25cfb95f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Inicjalizacja optymalizatora\n",
    "optimizer = AdamW(model.parameters(),lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1702507945246,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "GJXdVM18R3YD",
    "outputId": "05b20ea8-5080-495d-a772-62a291e06245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [0.57743559 3.72848948]\n"
     ]
    }
   ],
   "source": [
    "# Obliczenie wag klas\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702507945246,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "Tktlzc_LSDLH"
   },
   "outputs": [],
   "source": [
    "# Konwersja listy z wagami klas do typu tensorowego\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# Przeniesienie wag do pamięci domyślnego urządzenia\n",
    "weights = weights.to(device)\n",
    "\n",
    "# Określenie funkcji straty\n",
    "cross_entropy  = nn.NLLLoss(weight=weights)\n",
    "\n",
    "# Określenie liczby epok\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzP0IoktSw3T"
   },
   "source": [
    "<h2>Kalibracja modelu (ang. fine-tuning)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702507945246,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "iJDBj4WFS4jD"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    model.train()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # przygotowanie listy do przechowywania predykcji modelu\n",
    "    total_preds=[]\n",
    "\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        batch = [r.to(device) for r in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # Normalizacja wartości gradientów\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    total_preds.append(preds)\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # Predykcje modelu mają wymiary (liczba pakietów, rozmiar pakietu, liczba klas).\n",
    "    # Przekształcenie ich do wymiarów (liczba próbek, liczba klas)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702507945247,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "fvnoxaHxU5hT"
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "\n",
    "    print(\"\\nEvaluating...\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    total_preds = []\n",
    "\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92734,
     "status": "ok",
     "timestamp": 1702508037977,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "VDTfBKa9VOdP",
    "outputId": "4ec450a6-f3ef-4559-eb29-b695b67f5d88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.673\n",
      "Validation Loss: 0.649\n",
      "\n",
      " Epoch 2 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.641\n",
      "Validation Loss: 0.623\n",
      "\n",
      " Epoch 3 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.619\n",
      "Validation Loss: 0.595\n",
      "\n",
      " Epoch 4 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.594\n",
      "Validation Loss: 0.568\n",
      "\n",
      " Epoch 5 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.570\n",
      "Validation Loss: 0.544\n",
      "\n",
      " Epoch 6 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.550\n",
      "Validation Loss: 0.533\n",
      "\n",
      " Epoch 7 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.527\n",
      "Validation Loss: 0.499\n",
      "\n",
      " Epoch 8 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.508\n",
      "Validation Loss: 0.487\n",
      "\n",
      " Epoch 9 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.486\n",
      "Validation Loss: 0.460\n",
      "\n",
      " Epoch 10 / 10\n",
      "  Batch    50  of    122.\n",
      "  Batch   100  of    122.\n",
      "\n",
      "Evaluating...\n",
      "\n",
      "Training Loss: 0.475\n",
      "Validation Loss: 0.452\n"
     ]
    }
   ],
   "source": [
    "# Inicjalizacja początkowej wartości funkcji straty\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# Inicjalizacja list na wartości funkcji straty na zbiorze uczącym i walidacyjnym\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "\n",
    "    train_loss, _ = train()\n",
    "\n",
    "    valid_loss, _ = evaluate()\n",
    "\n",
    "    # zapisanie najlepszego modelu\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1702508038394,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "UMiAkW3IVoZC",
    "outputId": "484c4219-8067-4e8a-86f4-ac8b71bc417a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytanie wartości parametrów najlepszego modelu\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vbi1WgVaV2kB"
   },
   "source": [
    "<h2>Wygenerowanie predykcji za pomocą skalibrowanego modelu oraz ocena ich jakości</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 1095,
     "status": "ok",
     "timestamp": 1702508039487,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "l5zmee6LVzUN"
   },
   "outputs": [],
   "source": [
    "# Wygenerowanie predykcji dla zbioru testowego\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702508039488,
     "user": {
      "displayName": "Kamil Kanclerz",
      "userId": "06436031169764615040"
     },
     "user_tz": -60
    },
    "id": "RL59FeOAWGVd",
    "outputId": "8fcc7dcc-e53a-41be-be46-b9ab4a4137da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.88       724\n",
      "           1       0.40      0.88      0.54       112\n",
      "\n",
      "    accuracy                           0.80       836\n",
      "   macro avg       0.69      0.83      0.71       836\n",
      "weighted avg       0.90      0.80      0.83       836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ocena jakości predykcji modelu\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
